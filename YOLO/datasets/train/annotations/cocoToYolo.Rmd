

Mash coco into yolo format 

```{r}
library(jsonlite)
test <- fromJSON('/media/tad/sanDisk1TB/Science/beetlecounting/YOLO/datasets/train/annotations/instances_default.json' )

test$annotations$bbox


# needs to have labels folder with one txt file per image 
# 5 entries per line (category (1); then coordinates of bbox)


# only images 1-9 and 14 have annotations
images <- test$image$id[c(1:9, 14)]
imageNames <- test$image$file_name[c(1:9, 14)]
imageNames <- gsub('.JPG', '', imageNames)
truth <- c()

for(i in 1:length(images)){
  tmp <- test$annotations[which(test$annotations$image_id == images[i]),]
  tmpInfo <- test$images[which(test$images$id == images[i]),]
  tmp2 <- cbind(0, do.call(rbind, tmp$bbox))
  truth[i] <- nrow(tmp)

# coco and yolo format for bbox are different (which is silly)
  xyolo <- (tmp2[,2] + (tmp2[,4]/2)) / tmpInfo$width
  yyolo <- (tmp2[,3] + (tmp2[,5]/2)) / tmpInfo$height
  wyolo <- tmp2[,4] / tmpInfo$width
  hyolo <- tmp2[,5] / tmpInfo$height

  tmpYolo <- cbind(tmp2[,1], xyolo, yyolo, wyolo, hyolo)
  
  # print(range(xyolo+wyolo))
  # print(range(yyolo+hyolo))
  # print(range(xyolo-wyolo))
  # print(range(yyolo-hyolo))

  write.table(tmpYolo, file=paste(imageNames[i], '.txt', sep=''), 
    row.names=FALSE, col.names=FALSE)
}

truthDF <- data.frame(imageNames, truth)


# when i=2 from above
library(imager)
image <- load.image('/media/tad/sanDisk1TB/Science/beetlecounting/YOLO/datasets/train/images/A6_257_0416.JPG')
plot(image)
#points(x=tmp2[,2], y=tmp2[,3], pch=16, col='red')
rect(xleft=tmp2[,2], 
  xright=tmp2[,2]+tmp2[,4], 
  ybottom=tmp2[,3]+tmp2[,5], 
  ytop=tmp2[,3])


```













Python code attempting to validate the placement of the annotated bboxes in the real image. It crashes my computer because of library garbage with qt5. 


```{python}

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import cv2
import matplotlib.pyplot as plt

image_BGR = cv2.imread('images/A6_257_0416.jpg')
print('Image shape:', image_BGR.shape)
h, w = image_BGR.shape[:2]

with open('labels/A6_257_0416.txt') as f:
   lst = []
   for line in f:
      lst += [line.rstrip()]
      print(line)

# Going through all BB
for i in range(len(lst)):
   # Getting current bounding box coordinates, its width and height
    bb_current = lst[i].split()
    x_center, y_center = int(float(bb_current[1]) * w), int(float(bb_current[2]) * h)
    box_width, box_height = int(float(bb_current[3]) * w), int(float(bb_current[4]) * h)
   # Now, from YOLO data format, we can get top left corner coordinates
   # that are x_min and y_min
    x_min = int(x_center - (box_width / 2))
    y_min = int(y_center - (box_height / 2))
   # Drawing bounding box on the original image
    cv2.rectangle(image_BGR, (x_min, y_min), (x_min + box_width, y_min + box_height), [172 , 10, 127], 2)


plt.rcParams['figure.figsize'] = (15, 15)

plt.imshow(cv2.cvtColor(image_BGR, cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.title('Image 00003.jpg with Traffic Signs', fontsize=18)

# Showing the plot
plt.show()


```






## get predictions from best fit model


```{python}

from ultralytics import YOLO

# Load a pretrained YOLOv8n model
model = YOLO("best.pt")

# Run inference on an image
results = model(["../images/A10_336_0416.JPG",
 "../images/A6_257_0416.JPG",
 "../images/A9_311_0416.JPG",
 "../images/C1_330_43024.JPG",
 "../images/C10_211_43024.JPG",
 "../images/C2_160_43024.JPG",
 "../images/C3_304_43024.JPG",
 "../images/C8_288_43024.JPG"])

```


